{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec33d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Need to remove unrelevant\n",
    "from time import sleep\n",
    "import asyncio\n",
    "import glob\n",
    "import os\n",
    "import bs4\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lxml import html\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium_pro import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from requests_html import AsyncHTMLSession\n",
    "import pyppdf.patch_pyppeteer\n",
    "from element_manager import *\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ddbb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n4/1qjz2d_11qd3rqyzd80gtgy4mh6y7w/T/ipykernel_5651/2965352831.py:9: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(executable_path='/Users/alevi/Downloads/chromedriver_mac64/chromedriver', chrome_options=chrome_options)\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".manhattan--container--1lP57Ag\"}\n  (Session info: chrome=113.0.5672.92)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n4/1qjz2d_11qd3rqyzd80gtgy4mh6y7w/T/ipykernel_5651/2965352831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# wait for the page to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mwait\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisibility_of_element_located\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"manhattan--container--1lP57Ag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# get all the product items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/support/expected_conditions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, driver)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_element_if_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_find_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStaleElementReferenceException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/support/expected_conditions.py\u001b[0m in \u001b[0;36m_find_element\u001b[0;34m(driver, by)\u001b[0m\n\u001b[1;32m    409\u001b[0m     if thrown.\"\"\"\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium_pro/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[name=\"%s\"]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             'value': value})['value']\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium_pro/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    326\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium_pro/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".manhattan--container--1lP57Ag\"}\n  (Session info: chrome=113.0.5672.92)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path='/Users/alevi/Downloads/chromedriver_mac64/chromedriver')\n",
    "prices=[]\n",
    "names=[]\n",
    "\n",
    "# Navigate to the AliExpress website\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"−−lang=en\")\n",
    "driver = webdriver.Chrome(executable_path='/Users/alevi/Downloads/chromedriver_mac64/chromedriver', chrome_options=chrome_options)\n",
    "\n",
    "driver.get(\"https://www.aliexpress.com/category/100003070/men-clothing.html?category_redirect=1&spm=a2g0o.home.102.1.650c2145PqC2Kt\")\n",
    "\n",
    "\n",
    "# wait for the page to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.visibility_of_element_located((By.CLASS_NAME, \"manhattan--container--1lP57Ag\")))\n",
    "\n",
    "# get all the product items\n",
    "product_items = driver.find_elements_by_class_name(\"manhattan--container--1lP57Ag\")\n",
    "\n",
    "# loop through each product item and click it\n",
    "for item in product_items:\n",
    "    item.click()\n",
    "    # wait for the price to load\n",
    "    #wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \".product-price-value\")))\n",
    "    \n",
    "    # get the price and append it to the list\n",
    "    #price = driver.find_element_by_css_selector(\".product-price-value\").text\n",
    "    price = driver.find_element_by_class_name(\"product-price-value\").text\n",
    "    prices.append(price)\n",
    "\n",
    "# close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b69cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc height=>4467\tpages =>5\n",
      "scrolling to=>786\n",
      "scrolling to=>1572\n",
      "scrolling to=>2358\n",
      "scrolling to=>3144\n",
      "scrolling to=>3930\n",
      "['₪18.05', '₪30.58', '₪14.61', '₪18.89', '₪23.65', '₪18.77', '₪23.88', '₪18.66', '₪23.91', '₪144.82', '₪17.88', '₪1.83', '₪19.07', '₪12.78', '₪61.63', '₪9.61', '₪36.02', '₪45.03', '₪18.81', '₪26.63', '₪15.1', '₪8.75', '₪18.44', '₪7.56', '₪46.38', '₪44.74', '₪21.27', '₪12.25', '₪21.34', '₪45.03', '₪7.6', '₪15.09', '₪6.44', '₪10.24', '₪18.78', '₪23.32', '₪13.74', '₪21.34', '₪1.83', '₪17.25', '₪7.85', '₪56.86', '₪19.63', '₪22.88', '₪50.32', '₪21.75', '₪12.4', '₪36.14', '₪99.08', '₪43.8', '₪1.83', '₪11.29', '₪20.59', '₪17.32', '₪40.73', '₪11.17']\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "##The Good One\n",
    "# Create a WebDriver object\n",
    "driver = webdriver.Chrome(executable_path='/Users/alevi/Downloads/chromedriver_mac64/chromedriver')\n",
    "prices=[]\n",
    "names=[]\n",
    "\n",
    "# Navigate to the AliExpress website\n",
    "driver.get(\"https://www.aliexpress.com/category/100003070/men-clothing.html?category_redirect=1&spm=a2g0o.home.102.1.650c2145PqC2Kt\")\n",
    "\n",
    "# # Change language to English\n",
    "# lang_btn = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \".switcher-info .language_txt\")))\n",
    "# lang_btn.click()\n",
    "\n",
    "# en_lang_btn = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[data-locale='en_US']\")))\n",
    "# en_lang_btn.click()\n",
    "\n",
    "\n",
    "doc_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "win_height = driver.execute_script(\"return window.innerHeight\")\n",
    "num_pages = int(doc_height / win_height)\n",
    "print(f'doc height=>{doc_height}\\tpages =>{num_pages}')\n",
    "# scroll through the document\n",
    "for page in range(num_pages):\n",
    "    driver.execute_script(\"window.scrollTo(0, arguments[0]);\", win_height * (page+1))\n",
    "    print(f'scrolling to=>{win_height * (page+1)}')\n",
    "    sleep(2)\n",
    "\n",
    "\n",
    "# Wait for all product elements to be visible\n",
    "product_elements = WebDriverWait(driver, 10).until(EC.visibility_of_all_elements_located((By.CLASS_NAME, 'manhattan--content--1KpBbUi')))\n",
    "\n",
    "# Extract the name and price of each product and print it\n",
    "for product_element in product_elements:\n",
    "    # Find the price element within the parent element\n",
    "    price_element = product_element.find_element_by_class_name('manhattan--price-sale--1CCSZfK')\n",
    "    price_text = price_element.text\n",
    "\n",
    "    # Append the price text to the prices list\n",
    "    prices.append(price_text)\n",
    "\n",
    "#driver.quit()\n",
    "print(prices)\n",
    "print(len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7024cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['₪30.54', '₪12.74', '₪18.72', '₪1.82', '₪44.02', '₪15.08', '₪14.59', '₪18.84', '₪18.61', '₪74.51', '₪18.87', '₪19.02', '₪1.82', '₪70.19', '₪36.26', '₪80.69', '₪107.11', '₪50.26', '₪10.36', '₪10.22', '₪28.23', '₪84.43', '₪12.37', '₪54.07']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "##The Good One\n",
    "# Create a WebDriver object\n",
    "driver = webdriver.Chrome(executable_path='/Users/alevi/Downloads/chromedriver_mac64/chromedriver')\n",
    "prices=[]\n",
    "names=[]\n",
    "\n",
    "# Navigate to the AliExpress website\n",
    "driver.get(\"https://www.aliexpress.com/category/100003070/men-clothing.html?category_redirect=1&spm=a2g0o.home.102.1.650c2145PqC2Kt\")\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Wait for all product elements to be visible\n",
    "product_elements = WebDriverWait(driver, 10).until(EC.visibility_of_all_elements_located((By.CLASS_NAME, 'manhattan--content--1KpBbUi')))\n",
    "\n",
    "# Extract the name and price of each product and print it\n",
    "for product_element in product_elements:\n",
    "    # Find the price element within the parent element\n",
    "    price_element = product_element.find_element_by_class_name('manhattan--price-sale--1CCSZfK')\n",
    "    price_text = price_element.text\n",
    "\n",
    "    # Append the price text to the prices list\n",
    "    prices.append(price_text)\n",
    "\n",
    "#driver.quit()\n",
    "print(prices)\n",
    "print(len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de5a4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def data_from_url(url):\n",
    "    # Set up the driver\n",
    "    #driver = webdriver.Chrome(executable_path='/Users/alevi/Downloads/chromedriver_mac64/chromedriver')\n",
    "    # Set up the driver with headless option\n",
    "#     chrome_options = Options()\n",
    "#     chrome_options.add_argument('--headless')\n",
    "#     chrome_options.add_argument('--disable-gpu')\n",
    "#     driver = webdriver.Chrome('/Users/alevi/Downloads/chromedriver_mac64/chromedriver', options=chrome_options)\n",
    "    driver = webdriver.Chrome(executable_path='/Users/alevi/Downloads/chromedriver_mac64/chromedriver')\n",
    "    # Define the URLs to scrape\n",
    "    product_urls = []\n",
    "    titles = []\n",
    "    stars = []\n",
    "    ratings_count = []\n",
    "    prices = []\n",
    "    orders_count = []\n",
    "    seller_rating = []\n",
    "    seller_followers = []\n",
    "    shipping = []\n",
    "    likes = []\n",
    "    discounts = []\n",
    "\n",
    "    #Navigate to the AliExpress website and get all the product item URLs\n",
    "    # driver.get(base_url)\n",
    "    # wait = WebDriverWait(driver, 10)\n",
    "    i=1\n",
    "    for i in range(50):\n",
    "        if 'women' in url:\n",
    "            url = f\"https://www.aliexpress.com/category/100003109/women-clothing.html?CatId=100003109&category_redirect=1&g=y&isCategoryBrowse=true&isrefine=y&page={i}&spm=a2g0o.home.101.1.1e8c6b05iRrE2j&trafficChannel=main\"\n",
    "        else:\n",
    "            url = f\"https://www.aliexpress.com/category/100003070/men-clothing.html?CatId=100003070&category_redirect=2&g=y&isCategoryBrowse=true&isrefine=y&page={i}&spm=a2g0o.home.102.1.650c2145PqC2Kt&trafficChannel=main\"\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        doc_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        win_height = driver.execute_script(\"return window.innerHeight\")\n",
    "        num_pages = int(doc_height / win_height)\n",
    "        print(f'doc height=>{doc_height}\\tpages =>{num_pages}')\n",
    "        # scroll through the document\n",
    "        for page in range(num_pages):\n",
    "            driver.execute_script(\"window.scrollTo(0, arguments[0]);\", win_height * (page+1))\n",
    "            print(f'scrolling to=>{win_height * (page+1)}')\n",
    "            sleep(2)\n",
    "\n",
    "        wait.until(EC.visibility_of_element_located((By.CLASS_NAME, \"manhattan--container--1lP57Ag\")))\n",
    "\n",
    "        product_items = driver.find_elements_by_class_name(\"manhattan--container--1lP57Ag\")\n",
    "\n",
    "        for item in product_items:\n",
    "            product_urls.append(item.get_attribute(\"href\"))\n",
    "\n",
    "        # Loop through each product item URL and fetch the price using BeautifulSoup\n",
    "\n",
    "        for url in product_urls:\n",
    "            driver.get(url)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            asession = AsyncHTMLSession()\n",
    "            r = await asession.get(url)\n",
    "            await r.html.arender(timeout=30000)\n",
    "            ##stars##\n",
    "            star_obj = r.html.find('.overview-rating-average')\n",
    "            if len(star_obj) > 0:\n",
    "                star = star_obj[0].text\n",
    "            else:\n",
    "                star = None\n",
    "            stars.append(star)\n",
    "            #####\n",
    "            ##rating_counts##\n",
    "            rating_obj = r.html.find('.product-reviewer-reviews')\n",
    "            if len(rating_obj) > 0:\n",
    "                rating_counts = rating_obj[0].text.replace(' חוות דעת','').strip()\n",
    "            else:\n",
    "                rating_counts = None\n",
    "            ratings_count.append(rating_counts)\n",
    "            ####\n",
    "            ##prices##\n",
    "            price_obj = r.html.find('.product-price-value')\n",
    "            if len(price_obj) > 0:\n",
    "                price = price_obj[0].text.replace('₪ ','').strip()\n",
    "            else:\n",
    "                price = None\n",
    "            prices.append(price)\n",
    "            ####\n",
    "            ##orders_count##\n",
    "            orders_count_obj = r.html.find('.product-reviewer-sold')\n",
    "            if len(orders_count_obj) > 0:\n",
    "                orders = orders_count_obj[0].text.replace('+ הזמנות','').strip()\n",
    "            else:\n",
    "                orders = None\n",
    "            orders_count.append(orders)\n",
    "            ##seller_rating##\n",
    "            seller_rating_obj = r.html.find('span[data-role=\"positive-feedback\"] i')\n",
    "            if len(seller_rating_obj) > 0:\n",
    "                seller_rating_text = seller_rating_obj[0].text.replace('%','').strip()\n",
    "            else:\n",
    "                seller_rating_text = None\n",
    "            seller_rating.append(seller_rating_text)\n",
    "            ##seller_followers##\n",
    "            seller_follows_obj = r.html.find('p[class=\"num-followers\"] i')\n",
    "            if len(seller_follows_obj) > 0:\n",
    "                seller_followers_text = seller_follows_obj[0].text.strip()\n",
    "            else:\n",
    "                seller_followers_text = None\n",
    "            seller_followers.append(seller_followers_text)\n",
    "            ####\n",
    "            ##shpping##\n",
    "            shipping_obj = r.html.find('strong:contains(\"Free Shipping\")')\n",
    "            if len(shipping_obj) > 0:\n",
    "                shipping_stat = shipping_obj[0].text\n",
    "                if shipping_stat == \"Free Shipping\":\n",
    "                    shipping_res = 1\n",
    "                else:\n",
    "                    shipping_res = 0\n",
    "            else:\n",
    "                shipping_res = 0\n",
    "            shipping.append(shipping_res)\n",
    "            ####\n",
    "            ##likes##\n",
    "            likes_obj = r.html.find('span.add-wishlist-num')\n",
    "            if len(likes_obj) > 0:\n",
    "                likes_count = likes_obj[0].text\n",
    "            else:\n",
    "                likes_count = None\n",
    "            likes.append(likes_count)\n",
    "            ####\n",
    "            ##titles##\n",
    "            title_obj = r.html.find('h1')\n",
    "            title = title_obj[0].text\n",
    "            titles.append(title)\n",
    "            ####\n",
    "            ##discounts##\n",
    "            discount_obj = r.html.find('span.product-price-mark')\n",
    "            if len(discount_obj) > 0:\n",
    "                discount = 1\n",
    "            else:\n",
    "                discount = 0\n",
    "            discounts.append(discount)\n",
    "        product_urls.clear()\n",
    "\n",
    "    # dictionary of lists \n",
    "    dict = {'Titels': titles, 'Prices': prices, 'Stars': stars, 'Orders_Count': orders_count, 'Seller_Rating': seller_rating, 'Seller_Followers': seller_followers, 'Shipping': shipping, 'Likes': likes, 'Discounts': discounts} \n",
    "    df = pd.DataFrame(dict)\n",
    "    if 'women' in url:\n",
    "        df.to_csv('womens.csv', index=False)\n",
    "    else:\n",
    "        df.to_csv('mens.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Close the driver\n",
    "\n",
    "# print(ratings_count)\n",
    "# print(len(ratings_count))\n",
    "# print(len(prices))\n",
    "# print(prices)\n",
    "# print(len(likes))\n",
    "# print(len(seller_rating))\n",
    "# print(len(orders_count))\n",
    "# print(len(seller_followers))\n",
    "# print(len(shipping))\n",
    "# print(len(titles))\n",
    "# print(discounts)\n",
    "# print(len(discounts))\n",
    "\n",
    "#driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc height=>1282\tpages =>2\n",
      "scrolling to=>600\n",
      "scrolling to=>1200\n",
      "doc height=>4620\tpages =>7\n",
      "scrolling to=>600\n",
      "scrolling to=>1200\n",
      "scrolling to=>1800\n",
      "scrolling to=>2400\n",
      "scrolling to=>3000\n",
      "scrolling to=>3600\n",
      "scrolling to=>4200\n",
      "doc height=>4622\tpages =>7\n",
      "scrolling to=>600\n",
      "scrolling to=>1200\n",
      "scrolling to=>1800\n",
      "scrolling to=>2400\n",
      "scrolling to=>3000\n",
      "scrolling to=>3600\n",
      "scrolling to=>4200\n",
      "doc height=>4540\tpages =>7\n",
      "scrolling to=>600\n",
      "scrolling to=>1200\n",
      "scrolling to=>1800\n",
      "scrolling to=>2400\n",
      "scrolling to=>3000\n",
      "scrolling to=>3600\n",
      "scrolling to=>4200\n",
      "doc height=>4559\tpages =>7\n",
      "scrolling to=>600\n",
      "scrolling to=>1200\n",
      "scrolling to=>1800\n",
      "scrolling to=>2400\n",
      "scrolling to=>3000\n",
      "scrolling to=>3600\n",
      "scrolling to=>4200\n",
      "doc height=>4630\tpages =>7\n",
      "scrolling to=>600\n",
      "scrolling to=>1200\n",
      "scrolling to=>1800\n",
      "scrolling to=>2400\n",
      "scrolling to=>3000\n",
      "scrolling to=>3600\n",
      "scrolling to=>4200\n"
     ]
    }
   ],
   "source": [
    "url_women = \"https://www.aliexpress.com/category/100003109/women-clothing.html?CatId=100003109&category_redirect=1&g=y&isCategoryBrowse=true&isrefine=y&page=1&spm=a2g0o.home.101.1.1e8c6b05iRrE2j&trafficChannel=main\"\n",
    "url_men = \"https://www.aliexpress.com/category/100003070/men-clothing.html?CatId=100003070&category_redirect=2&g=y&isCategoryBrowse=true&isrefine=y&page=1&spm=a2g0o.home.102.1.650c2145PqC2Kt&trafficChannel=main\"\n",
    "df_women = await data_from_url(url_women)\n",
    "df_man = await data_from_url(url_men)\n",
    "# translator = Translator()\n",
    "# df['Titels'] = df['Titels'].apply(lambda x: translator.translate(x, src='he', dest='en').text)\n",
    "#df\n",
    "# detector = Translator()\n",
    "\n",
    "# dec_lan = detector.detect('שלום')\n",
    "\n",
    "# print(dec_lan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f9aef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp_data_delete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b71cc6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower then 4 \n",
    "\n",
    "# Identify the subset of rows where 'Stars' is lower than 4\n",
    "subset = df[df['Stars'] < 4]\n",
    "\n",
    "# Randomly select 1/3 of the rows from the subset\n",
    "num_rows = subset.shape[0]\n",
    "num_rows_third = num_rows // 2\n",
    "random_rows = np.random.choice(subset.index, size=num_rows_third, replace=False)\n",
    "\n",
    "# Update the selected rows with the desired values\n",
    "df.loc[random_rows, 'Orders_Count'] = np.random.randint(1, 500, size=num_rows_third)\n",
    "df.loc[random_rows, 'Seller_Rating'] = np.random.uniform(50, 65, size=num_rows_third)\n",
    "df.loc[random_rows, 'Seller_Followers'] = np.random.randint(50, 151, size=num_rows_third)\n",
    "df.loc[random_rows, 'Shipping'] = 0\n",
    "df.loc[random_rows, 'Discounts'] = 0\n",
    "df.loc[random_rows, 'Likes'] = np.random.randint(0, 51, size=num_rows_third)\n",
    "\n",
    "# Fill NA values in 'Shipping' and 'Discounts' columns with 0\n",
    "df['Shipping'] = df['Shipping'].fillna(0)\n",
    "df['Discounts'] = df['Discounts'].fillna(0)\n",
    "\n",
    "#higher then 4\n",
    "# Identify the subset of rows where 'Stars' is higher than 4\n",
    "subset = df[df['Stars'] > 4]\n",
    "\n",
    "# Randomly select half of the rows from the subset\n",
    "num_rows = subset.shape[0]\n",
    "num_rows_half = num_rows // 2\n",
    "random_rows = np.random.choice(subset.index, size=num_rows_half, replace=False)\n",
    "\n",
    "# Update the selected rows with the desired values\n",
    "df.loc[random_rows, 'Orders_Count'] = np.random.randint(80, 1001, size=num_rows_half)\n",
    "\n",
    "# Add some outliers to the selected rows in 'Orders_Count' column\n",
    "outliers = np.random.choice(random_rows, size=int(num_rows_half*0.05), replace=False)\n",
    "df.loc[outliers, 'Orders_Count'] = np.random.randint(900, 2200, size=int(num_rows_half*0.05))\n",
    "\n",
    "df.loc[random_rows, 'Seller_Rating'] = np.random.uniform(80, 100, size=num_rows_half)\n",
    "df.loc[random_rows, 'Seller_Followers'] = np.random.randint(200, 2001, size=num_rows_half)\n",
    "df.loc[random_rows, 'Shipping'] = np.random.choice([0, 1], size=num_rows_half, p=[0.5, 0.5])\n",
    "df.loc[random_rows, 'Discounts'] = np.random.choice([0, 1], size=num_rows_half, p=[0.5, 0.5])\n",
    "df.loc[random_rows, 'Likes'] = np.random.randint(200, 1001, size=num_rows_half)\n",
    "\n",
    "subset = df[df['Stars'] == 5]\n",
    "\n",
    "# Randomly select one-third of the rows from the subset\n",
    "num_rows = subset.shape[0]\n",
    "num_rows_third = num_rows // 2\n",
    "random_rows = np.random.choice(subset.index, size=num_rows_third, replace=False)\n",
    "\n",
    "# Update the selected rows with the desired values\n",
    "df.loc[random_rows, 'Orders_Count'] = np.random.randint(1, 201, size=num_rows_third)\n",
    "\n",
    "# Fill NA values in 'Shipping' and 'Discounts' columns with 1\n",
    "df['Shipping'] = df['Shipping'].fillna(1)\n",
    "df['Discounts'] = df['Discounts'].fillna(1)\n",
    "df.to_csv('manip.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5b70d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#lower than 4\n",
    "\n",
    "# Identify the subset of rows where 'Stars' is lower than 4\n",
    "subset = df[df['Stars'] < 4]\n",
    "\n",
    "# Randomly select 1/3 of the rows from the subset\n",
    "num_rows = subset.shape[0]\n",
    "num_rows_third = num_rows // 2\n",
    "random_rows = np.random.choice(subset.index, size=num_rows_third, replace=False)\n",
    "\n",
    "# Update the selected rows with the desired values\n",
    "df.loc[random_rows, 'Orders_Count'] = np.random.randint(1, 500, size=num_rows_third)\n",
    "df.loc[random_rows, 'Seller_Rating'] = np.random.uniform(50, 65, size=num_rows_third)\n",
    "df.loc[random_rows, 'Seller_Followers'] = np.random.randint(50, 151, size=num_rows_third)\n",
    "df.loc[random_rows, 'Shipping'] = 0\n",
    "df.loc[random_rows, 'Discounts'] = 0\n",
    "df.loc[random_rows, 'Likes'] = np.random.randint(0, 51, size=num_rows_third)\n",
    "\n",
    "# Fill NA values in 'Shipping' and 'Discounts' columns with 0\n",
    "df['Shipping'] = df['Shipping'].fillna(0)\n",
    "df['Discounts'] = df['Discounts'].fillna(0)\n",
    "\n",
    "#higher than 4\n",
    "\n",
    "# Identify the subset of rows where 'Stars' is higher than 4\n",
    "subset = df[df['Stars'] > 4]\n",
    "\n",
    "# Randomly select half of the rows from the subset\n",
    "num_rows = subset.shape[0]\n",
    "num_rows_half = num_rows // 2\n",
    "random_rows = np.random.choice(subset.index, size=num_rows_half, replace=False)\n",
    "\n",
    "# Update the selected rows with the desired values\n",
    "df.loc[random_rows, 'Orders_Count'] = np.random.randint(80, 1001, size=num_rows_half)\n",
    "\n",
    "# Add outliers to 'Seller_Rating' column in the selected rows\n",
    "outlier_fraction_rating = 0.1\n",
    "outlier_rows_rating = np.random.choice(random_rows, size=int(num_rows_half * outlier_fraction_rating), replace=False)\n",
    "df.loc[outlier_rows_rating, 'Seller_Rating'] = np.random.uniform(30, 100, size=int(num_rows_half * outlier_fraction_rating))\n",
    "\n",
    "# Add outliers to 'Seller_Followers' column in the selected rows\n",
    "outlier_fraction_followers = 0.1\n",
    "outlier_rows_followers = np.random.choice(random_rows, size=int(num_rows_half * outlier_fraction_followers), replace=False)\n",
    "df.loc[outlier_rows_followers, 'Seller_Followers'] = np.random.randint(100, 10000, size=int(num_rows_half * outlier_fraction_followers))\n",
    "\n",
    "# Update the remaining rows with regular values\n",
    "non_outlier_rows = np.setdiff1d(random_rows, np.concatenate((outlier_rows_rating, outlier_rows_followers)))\n",
    "df.loc[non_outlier_rows, 'Seller_Rating'] = np.random.uniform(80, 100, size=len(non_outlier_rows))\n",
    "df.loc[non_outlier_rows, 'Seller_Followers'] = np.random.randint(200, 2001, size=len(non_outlier_rows))\n",
    "df.loc[non_outlier_rows, 'Shipping'] = np.random.choice([0, 1], size=len(non_outlier_rows), p=[0.5, 0.5])\n",
    "df.loc[non_outlier_rows, 'Discounts'] = np.random.choice([0, 1], size=len(non_outlier_rows), p=[0.5, 0.5])\n",
    "\n",
    "df.to_csv('manip2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
